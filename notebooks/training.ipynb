{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "564128a3-d54e-42f7-8e66-81f617d66125",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731f43f2-ed9f-4b26-a12b-e4a72ea20f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install datasets==2.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b362d237-dcfc-4b7e-b74f-4560cdc06d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf86653-c4d8-4838-aa2f-da1b71379f89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install transformers==4.26.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2278e7-765c-440d-bdaf-752bda8e04cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install evaluate==0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e1fc8-f357-4ca0-b7a8-038128db96ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1addf4d-34f1-443b-817d-00caacd38902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_save_path = './data/processed_dataset/test/'\n",
    "train_save_path = './data/processed_dataset/train/'\n",
    "val_save_path = './data/processed_dataset/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a9cfb9-e3d0-44c5-9c7c-27afca1fb1cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk\n",
    " \n",
    "test_dataset = load_from_disk(test_save_path)\n",
    "val_dataset = load_from_disk(val_save_path)\n",
    "train_dataset = load_from_disk(train_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae741f4e-0560-4536-844d-0df9c7d80255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import requests\n",
    "import torch\n",
    "from datasets import load_dataset, load_from_disk, Dataset, Features, Array3D\n",
    "from io import BytesIO\n",
    "from typing import Tuple\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62dcd53c-75df-4211-8009-4fa4db90d44b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, ViTFeatureExtractor, ViTForImageClassification, Trainer, TrainingArguments, default_data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50055f4-6434-4b47-bf0a-e18f2af478a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Check GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052a789c-0105-4693-90c8-4b4dd1cb118b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 1, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available(),torch.cuda.device_count(),torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8890810-f32c-4ae8-a708-a65376220e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.cuda.device at 0x220c084e710>, 'NVIDIA GeForce RTX 3080')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(0),torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dd9d3e-1991-4274-9be3-846fa81d3004",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Model initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b570aafb-19ba-494c-a276-fed32d9f2b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "test_size = 0.1\n",
    "model_name = \"google/vit-base-patch16-224-in21k\"\n",
    "num_classes = train_dataset.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7022b8c5-24a2-4b8d-b41e-41796eeebc75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\anaconda-dev-stand\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Download model from model hub\n",
    "# model = ViTForImageClassification(num_labels=num_classes).to(\"cuda\")\n",
    "model = ViTForImageClassification.from_pretrained(model_name, num_labels=num_classes).to(\"cuda\")\n",
    "# Download feature extractor from hub\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67aad956-5523-4277-949f-d08331677d56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# K for top accuracy metric\n",
    "k_for_top_acc = 1\n",
    "\n",
    "# Compute metrics function for binary classification\n",
    "acc_metric = evaluate.load(\"accuracy\", module_type=\"metric\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predicted_probs, labels = eval_pred\n",
    "    # Accuracy\n",
    "    predicted_labels = np.argmax(predicted_probs, axis=1)\n",
    "    acc = acc_metric.compute(predictions=predicted_labels, references=labels)\n",
    "    # Top-K Accuracy\n",
    "    top_k_indexes = [np.argpartition(row, -k_for_top_acc)[-k_for_top_acc:] for row in predicted_probs]\n",
    "    top_k_classes = [top_k_indexes[i][np.argsort(row[top_k_indexes[i]])] for i, row in enumerate(predicted_probs)]\n",
    "    top_k_classes = np.flip(np.array(top_k_classes), 1)\n",
    "    acc_k = {\n",
    "        f\"accuracy_k\" : sum([label in predictions for predictions, label in zip(top_k_classes, labels)]) / len(labels)\n",
    "    }\n",
    "    # Merge metrics\n",
    "    acc.update(acc_k)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6951ade0-8e8e-404e-b527-f4eefd2049fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change labels\n",
    "id2label = {key:train_dataset.features[\"label\"].names[index] for index,key in enumerate(model.config.id2label.keys())}\n",
    "label2id = {train_dataset.features[\"label\"].names[index]:value for index,value in enumerate(model.config.label2id.values())}\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1594d4c-7ce1-45e5-bc5a-f2dd436d97db",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90bdf7c7-1851-4d77-ad86-cd33c9e4053f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc9ff1e0-249f-485a-b816-9e4b82cecfe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_part = f\"{num_classes}_{format(datetime.datetime.now(), '%d%m%y_%H%M%S')}\"\n",
    "model_dir = f\"./model_large_{unique_part}\"\n",
    "output_data_dir = f\"./outputs_large_{unique_part}\"\n",
    "\n",
    "# Total number of training epochs to perform\n",
    "num_train_epochs = 30\n",
    "# The batch size per GPU/TPU core/CPU for training\n",
    "per_device_train_batch_size = 32\n",
    "# The batch size per GPU/TPU core/CPU for evaluation\n",
    "per_device_eval_batch_size = 64\n",
    "# The initial learning rate for AdamW optimizer\n",
    "learning_rate = 2e-5\n",
    "# Number of steps used for a linear warmup from 0 to learning_rate\n",
    "warmup_steps = 500\n",
    "# The weight decay to apply to all layers except all bias and LayerNorm weights in AdamW optimizer\n",
    "weight_decay = 0.01\n",
    "\n",
    "unique_part = f\"{num_classes}_{num_train_epochs}_{format(datetime.datetime.now(), '%d%m%y_%H%M%S')}\"\n",
    "model_dir = f\"./model_large_{unique_part}\"\n",
    "output_data_dir = f\"./outputs_large_{unique_part}\"\n",
    "\n",
    "\n",
    "main_metric_for_evaluation = \"accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c999848-64bf-4a36-9784-6a139679c035",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f613c899-392c-43a9-9878-96effe4cee52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = model_dir,\n",
    "    num_train_epochs = num_train_epochs,\n",
    "    per_device_train_batch_size = per_device_train_batch_size,\n",
    "    per_device_eval_batch_size = per_device_eval_batch_size,\n",
    "    warmup_steps = warmup_steps,\n",
    "    weight_decay = weight_decay,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    logging_strategy = \"epoch\",\n",
    "    logging_dir = f\"{output_data_dir}/logs\",\n",
    "    learning_rate = float(learning_rate),\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = main_metric_for_evaluation,\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    compute_metrics = compute_metrics,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = val_dataset,\n",
    "    data_collator = default_data_collator,\n",
    "    tokenizer = feature_extractor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3decdf9b-afcf-488a-ac9e-60a80afc9eea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda-dev-stand\\Lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 34421\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 32280\n",
      "  Number of trainable parameters = 85820957\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32280' max='32280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32280/32280 2:59:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Accuracy K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.766500</td>\n",
       "      <td>0.805173</td>\n",
       "      <td>0.843175</td>\n",
       "      <td>0.843175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.574100</td>\n",
       "      <td>0.513100</td>\n",
       "      <td>0.878849</td>\n",
       "      <td>0.878849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>0.386145</td>\n",
       "      <td>0.902734</td>\n",
       "      <td>0.902734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.364157</td>\n",
       "      <td>0.909544</td>\n",
       "      <td>0.909544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.348223</td>\n",
       "      <td>0.912593</td>\n",
       "      <td>0.912593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.383202</td>\n",
       "      <td>0.912389</td>\n",
       "      <td>0.912389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.403834</td>\n",
       "      <td>0.911881</td>\n",
       "      <td>0.911881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>0.460707</td>\n",
       "      <td>0.911983</td>\n",
       "      <td>0.911983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.466238</td>\n",
       "      <td>0.911170</td>\n",
       "      <td>0.911170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.497549</td>\n",
       "      <td>0.911475</td>\n",
       "      <td>0.911475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.517783</td>\n",
       "      <td>0.914117</td>\n",
       "      <td>0.914117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.534922</td>\n",
       "      <td>0.911780</td>\n",
       "      <td>0.911780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.557617</td>\n",
       "      <td>0.913914</td>\n",
       "      <td>0.913914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.633747</td>\n",
       "      <td>0.909035</td>\n",
       "      <td>0.909035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.589178</td>\n",
       "      <td>0.912085</td>\n",
       "      <td>0.912085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.626600</td>\n",
       "      <td>0.907206</td>\n",
       "      <td>0.907206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.618006</td>\n",
       "      <td>0.914727</td>\n",
       "      <td>0.914727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.635767</td>\n",
       "      <td>0.914016</td>\n",
       "      <td>0.914016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.658944</td>\n",
       "      <td>0.908527</td>\n",
       "      <td>0.908527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.677995</td>\n",
       "      <td>0.911881</td>\n",
       "      <td>0.911881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.656037</td>\n",
       "      <td>0.914117</td>\n",
       "      <td>0.914117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.741824</td>\n",
       "      <td>0.906190</td>\n",
       "      <td>0.906190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.668288</td>\n",
       "      <td>0.914829</td>\n",
       "      <td>0.914829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.667656</td>\n",
       "      <td>0.917878</td>\n",
       "      <td>0.917878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.680615</td>\n",
       "      <td>0.917370</td>\n",
       "      <td>0.917370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.684321</td>\n",
       "      <td>0.918691</td>\n",
       "      <td>0.918691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.697142</td>\n",
       "      <td>0.918183</td>\n",
       "      <td>0.918183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.700619</td>\n",
       "      <td>0.919301</td>\n",
       "      <td>0.919301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.709093</td>\n",
       "      <td>0.918793</td>\n",
       "      <td>0.918793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.709909</td>\n",
       "      <td>0.919097</td>\n",
       "      <td>0.919097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-1076\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-1076\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-1076\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-1076\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-2152\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-2152\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-2152\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-2152\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-3228\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-3228\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-3228\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-3228\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-4304\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-4304\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-4304\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-4304\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-5380\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-5380\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-5380\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-5380\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-6456\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-6456\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-6456\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-6456\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-7532\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-7532\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-7532\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-7532\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-8608\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-8608\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-8608\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-8608\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-9684\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-9684\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-9684\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-9684\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-10760\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-10760\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-10760\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-10760\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-11836\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-11836\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-11836\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-11836\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-12912\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-12912\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-12912\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-12912\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-13988\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-13988\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-13988\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-13988\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-15064\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-15064\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-15064\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-15064\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-16140\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-16140\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-16140\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-16140\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-17216\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-17216\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-17216\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-17216\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-18292\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-18292\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-18292\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-18292\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-19368\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-19368\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-19368\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-19368\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-20444\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-20444\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-20444\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-20444\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-21520\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-21520\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-21520\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-21520\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-22596\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-22596\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-22596\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-22596\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-23672\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-23672\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-23672\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-23672\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-24748\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-24748\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-24748\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-24748\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-25824\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-25824\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-25824\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-25824\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-26900\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-26900\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-26900\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-26900\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-27976\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-27976\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-27976\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-27976\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-29052\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-29052\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-29052\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-29052\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-30128\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-30128\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-30128\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-30128\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-31204\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-31204\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-31204\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-31204\\preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9839\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./model_large_29_30_280723_200223\\checkpoint-32280\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\checkpoint-32280\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\checkpoint-32280\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\checkpoint-32280\\preprocessor_config.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./model_large_29_30_280723_200223\\checkpoint-30128 (score: 0.9193007419453196).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=32280, training_loss=0.10811014241011539, metrics={'train_runtime': 10771.479, 'train_samples_per_second': 95.867, 'train_steps_per_second': 2.997, 'total_flos': 8.00399176062306e+19, 'train_loss': 0.10811014241011539, 'epoch': 30.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdea221-b31a-440b-be7d-358ae4c12062",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffaa4566-7e0e-4d24-b205-813dc87c05ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>step</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_accuracy_k</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1.7665</td>\n",
       "      <td>1.963751e-05</td>\n",
       "      <td>2152</td>\n",
       "      <td>0.805173</td>\n",
       "      <td>0.843175</td>\n",
       "      <td>0.843175</td>\n",
       "      <td>36.2830</td>\n",
       "      <td>271.174</td>\n",
       "      <td>4.244</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.5741</td>\n",
       "      <td>1.896035e-05</td>\n",
       "      <td>4304</td>\n",
       "      <td>0.513100</td>\n",
       "      <td>0.878849</td>\n",
       "      <td>0.878849</td>\n",
       "      <td>35.2488</td>\n",
       "      <td>279.130</td>\n",
       "      <td>4.369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.3260</td>\n",
       "      <td>1.828320e-05</td>\n",
       "      <td>6456</td>\n",
       "      <td>0.386145</td>\n",
       "      <td>0.902734</td>\n",
       "      <td>0.902734</td>\n",
       "      <td>35.4342</td>\n",
       "      <td>277.670</td>\n",
       "      <td>4.346</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.1988</td>\n",
       "      <td>1.760604e-05</td>\n",
       "      <td>8608</td>\n",
       "      <td>0.364157</td>\n",
       "      <td>0.909544</td>\n",
       "      <td>0.909544</td>\n",
       "      <td>35.5309</td>\n",
       "      <td>276.914</td>\n",
       "      <td>4.334</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.1236</td>\n",
       "      <td>1.692889e-05</td>\n",
       "      <td>10760</td>\n",
       "      <td>0.348223</td>\n",
       "      <td>0.912593</td>\n",
       "      <td>0.912593</td>\n",
       "      <td>35.3684</td>\n",
       "      <td>278.186</td>\n",
       "      <td>4.354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.0752</td>\n",
       "      <td>1.625173e-05</td>\n",
       "      <td>12912</td>\n",
       "      <td>0.383202</td>\n",
       "      <td>0.912389</td>\n",
       "      <td>0.912389</td>\n",
       "      <td>35.3165</td>\n",
       "      <td>278.595</td>\n",
       "      <td>4.361</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0.0464</td>\n",
       "      <td>1.557458e-05</td>\n",
       "      <td>15064</td>\n",
       "      <td>0.403834</td>\n",
       "      <td>0.911881</td>\n",
       "      <td>0.911881</td>\n",
       "      <td>35.3514</td>\n",
       "      <td>278.320</td>\n",
       "      <td>4.356</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0.0281</td>\n",
       "      <td>1.489742e-05</td>\n",
       "      <td>17216</td>\n",
       "      <td>0.460707</td>\n",
       "      <td>0.911983</td>\n",
       "      <td>0.911983</td>\n",
       "      <td>35.2646</td>\n",
       "      <td>279.005</td>\n",
       "      <td>4.367</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0.0227</td>\n",
       "      <td>1.422026e-05</td>\n",
       "      <td>19368</td>\n",
       "      <td>0.466238</td>\n",
       "      <td>0.911170</td>\n",
       "      <td>0.911170</td>\n",
       "      <td>35.2627</td>\n",
       "      <td>279.020</td>\n",
       "      <td>4.367</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.0150</td>\n",
       "      <td>1.354311e-05</td>\n",
       "      <td>21520</td>\n",
       "      <td>0.497549</td>\n",
       "      <td>0.911475</td>\n",
       "      <td>0.911475</td>\n",
       "      <td>35.2677</td>\n",
       "      <td>278.980</td>\n",
       "      <td>4.367</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>1.286595e-05</td>\n",
       "      <td>23672</td>\n",
       "      <td>0.517783</td>\n",
       "      <td>0.914117</td>\n",
       "      <td>0.914117</td>\n",
       "      <td>35.2966</td>\n",
       "      <td>278.752</td>\n",
       "      <td>4.363</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>0.0096</td>\n",
       "      <td>1.218880e-05</td>\n",
       "      <td>25824</td>\n",
       "      <td>0.534922</td>\n",
       "      <td>0.911780</td>\n",
       "      <td>0.911780</td>\n",
       "      <td>35.3006</td>\n",
       "      <td>278.721</td>\n",
       "      <td>4.363</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>0.0080</td>\n",
       "      <td>1.151164e-05</td>\n",
       "      <td>27976</td>\n",
       "      <td>0.557617</td>\n",
       "      <td>0.913914</td>\n",
       "      <td>0.913914</td>\n",
       "      <td>35.3624</td>\n",
       "      <td>278.233</td>\n",
       "      <td>4.355</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>0.0061</td>\n",
       "      <td>1.083449e-05</td>\n",
       "      <td>30128</td>\n",
       "      <td>0.633747</td>\n",
       "      <td>0.909035</td>\n",
       "      <td>0.909035</td>\n",
       "      <td>35.2747</td>\n",
       "      <td>278.926</td>\n",
       "      <td>4.366</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.0073</td>\n",
       "      <td>1.015733e-05</td>\n",
       "      <td>32280</td>\n",
       "      <td>0.589178</td>\n",
       "      <td>0.912085</td>\n",
       "      <td>0.912085</td>\n",
       "      <td>35.4462</td>\n",
       "      <td>277.576</td>\n",
       "      <td>4.345</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>0.0045</td>\n",
       "      <td>9.480176e-06</td>\n",
       "      <td>34432</td>\n",
       "      <td>0.626600</td>\n",
       "      <td>0.907206</td>\n",
       "      <td>0.907206</td>\n",
       "      <td>35.4093</td>\n",
       "      <td>277.865</td>\n",
       "      <td>4.349</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>0.0033</td>\n",
       "      <td>8.803021e-06</td>\n",
       "      <td>36584</td>\n",
       "      <td>0.618006</td>\n",
       "      <td>0.914727</td>\n",
       "      <td>0.914727</td>\n",
       "      <td>35.2098</td>\n",
       "      <td>279.439</td>\n",
       "      <td>4.374</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>0.0013</td>\n",
       "      <td>8.125865e-06</td>\n",
       "      <td>38736</td>\n",
       "      <td>0.635767</td>\n",
       "      <td>0.914016</td>\n",
       "      <td>0.914016</td>\n",
       "      <td>35.3415</td>\n",
       "      <td>278.398</td>\n",
       "      <td>4.357</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>0.0061</td>\n",
       "      <td>7.448710e-06</td>\n",
       "      <td>40888</td>\n",
       "      <td>0.658944</td>\n",
       "      <td>0.908527</td>\n",
       "      <td>0.908527</td>\n",
       "      <td>35.3754</td>\n",
       "      <td>278.131</td>\n",
       "      <td>4.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>6.771554e-06</td>\n",
       "      <td>43040</td>\n",
       "      <td>0.677995</td>\n",
       "      <td>0.911881</td>\n",
       "      <td>0.911881</td>\n",
       "      <td>35.7025</td>\n",
       "      <td>275.583</td>\n",
       "      <td>4.313</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>0.0017</td>\n",
       "      <td>6.094399e-06</td>\n",
       "      <td>45192</td>\n",
       "      <td>0.656037</td>\n",
       "      <td>0.914117</td>\n",
       "      <td>0.914117</td>\n",
       "      <td>35.5389</td>\n",
       "      <td>276.851</td>\n",
       "      <td>4.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>0.0011</td>\n",
       "      <td>5.417244e-06</td>\n",
       "      <td>47344</td>\n",
       "      <td>0.741824</td>\n",
       "      <td>0.906190</td>\n",
       "      <td>0.906190</td>\n",
       "      <td>35.4811</td>\n",
       "      <td>277.303</td>\n",
       "      <td>4.340</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>0.0015</td>\n",
       "      <td>4.740088e-06</td>\n",
       "      <td>49496</td>\n",
       "      <td>0.668288</td>\n",
       "      <td>0.914829</td>\n",
       "      <td>0.914829</td>\n",
       "      <td>35.7574</td>\n",
       "      <td>275.160</td>\n",
       "      <td>4.307</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>4.062933e-06</td>\n",
       "      <td>51648</td>\n",
       "      <td>0.667656</td>\n",
       "      <td>0.917878</td>\n",
       "      <td>0.917878</td>\n",
       "      <td>36.0625</td>\n",
       "      <td>272.832</td>\n",
       "      <td>4.270</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>3.385777e-06</td>\n",
       "      <td>53800</td>\n",
       "      <td>0.680615</td>\n",
       "      <td>0.917370</td>\n",
       "      <td>0.917370</td>\n",
       "      <td>36.0406</td>\n",
       "      <td>272.998</td>\n",
       "      <td>4.273</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.708622e-06</td>\n",
       "      <td>55952</td>\n",
       "      <td>0.684321</td>\n",
       "      <td>0.918691</td>\n",
       "      <td>0.918691</td>\n",
       "      <td>35.5360</td>\n",
       "      <td>276.875</td>\n",
       "      <td>4.334</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>2.031466e-06</td>\n",
       "      <td>58104</td>\n",
       "      <td>0.697142</td>\n",
       "      <td>0.918183</td>\n",
       "      <td>0.918183</td>\n",
       "      <td>35.4422</td>\n",
       "      <td>277.607</td>\n",
       "      <td>4.345</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.354311e-06</td>\n",
       "      <td>60256</td>\n",
       "      <td>0.700619</td>\n",
       "      <td>0.919301</td>\n",
       "      <td>0.919301</td>\n",
       "      <td>35.3734</td>\n",
       "      <td>278.147</td>\n",
       "      <td>4.354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>6.771554e-07</td>\n",
       "      <td>62408</td>\n",
       "      <td>0.709093</td>\n",
       "      <td>0.918793</td>\n",
       "      <td>0.918793</td>\n",
       "      <td>35.3744</td>\n",
       "      <td>278.139</td>\n",
       "      <td>4.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>96840</td>\n",
       "      <td>0.709909</td>\n",
       "      <td>0.919097</td>\n",
       "      <td>0.919097</td>\n",
       "      <td>35.3604</td>\n",
       "      <td>278.249</td>\n",
       "      <td>4.355</td>\n",
       "      <td>10771.479</td>\n",
       "      <td>95.867</td>\n",
       "      <td>2.997</td>\n",
       "      <td>8.003992e+19</td>\n",
       "      <td>0.10811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  learning_rate   step  eval_loss  eval_accuracy  \\\n",
       "epoch                                                           \n",
       "1.0    1.7665   1.963751e-05   2152   0.805173       0.843175   \n",
       "2.0    0.5741   1.896035e-05   4304   0.513100       0.878849   \n",
       "3.0    0.3260   1.828320e-05   6456   0.386145       0.902734   \n",
       "4.0    0.1988   1.760604e-05   8608   0.364157       0.909544   \n",
       "5.0    0.1236   1.692889e-05  10760   0.348223       0.912593   \n",
       "6.0    0.0752   1.625173e-05  12912   0.383202       0.912389   \n",
       "7.0    0.0464   1.557458e-05  15064   0.403834       0.911881   \n",
       "8.0    0.0281   1.489742e-05  17216   0.460707       0.911983   \n",
       "9.0    0.0227   1.422026e-05  19368   0.466238       0.911170   \n",
       "10.0   0.0150   1.354311e-05  21520   0.497549       0.911475   \n",
       "11.0   0.0130   1.286595e-05  23672   0.517783       0.914117   \n",
       "12.0   0.0096   1.218880e-05  25824   0.534922       0.911780   \n",
       "13.0   0.0080   1.151164e-05  27976   0.557617       0.913914   \n",
       "14.0   0.0061   1.083449e-05  30128   0.633747       0.909035   \n",
       "15.0   0.0073   1.015733e-05  32280   0.589178       0.912085   \n",
       "16.0   0.0045   9.480176e-06  34432   0.626600       0.907206   \n",
       "17.0   0.0033   8.803021e-06  36584   0.618006       0.914727   \n",
       "18.0   0.0013   8.125865e-06  38736   0.635767       0.914016   \n",
       "19.0   0.0061   7.448710e-06  40888   0.658944       0.908527   \n",
       "20.0   0.0024   6.771554e-06  43040   0.677995       0.911881   \n",
       "21.0   0.0017   6.094399e-06  45192   0.656037       0.914117   \n",
       "22.0   0.0011   5.417244e-06  47344   0.741824       0.906190   \n",
       "23.0   0.0015   4.740088e-06  49496   0.668288       0.914829   \n",
       "24.0   0.0004   4.062933e-06  51648   0.667656       0.917878   \n",
       "25.0   0.0001   3.385777e-06  53800   0.680615       0.917370   \n",
       "26.0   0.0001   2.708622e-06  55952   0.684321       0.918691   \n",
       "27.0   0.0001   2.031466e-06  58104   0.697142       0.918183   \n",
       "28.0   0.0001   1.354311e-06  60256   0.700619       0.919301   \n",
       "29.0   0.0001   6.771554e-07  62408   0.709093       0.918793   \n",
       "30.0   0.0001   0.000000e+00  96840   0.709909       0.919097   \n",
       "\n",
       "       eval_accuracy_k  eval_runtime  eval_samples_per_second  \\\n",
       "epoch                                                           \n",
       "1.0           0.843175       36.2830                  271.174   \n",
       "2.0           0.878849       35.2488                  279.130   \n",
       "3.0           0.902734       35.4342                  277.670   \n",
       "4.0           0.909544       35.5309                  276.914   \n",
       "5.0           0.912593       35.3684                  278.186   \n",
       "6.0           0.912389       35.3165                  278.595   \n",
       "7.0           0.911881       35.3514                  278.320   \n",
       "8.0           0.911983       35.2646                  279.005   \n",
       "9.0           0.911170       35.2627                  279.020   \n",
       "10.0          0.911475       35.2677                  278.980   \n",
       "11.0          0.914117       35.2966                  278.752   \n",
       "12.0          0.911780       35.3006                  278.721   \n",
       "13.0          0.913914       35.3624                  278.233   \n",
       "14.0          0.909035       35.2747                  278.926   \n",
       "15.0          0.912085       35.4462                  277.576   \n",
       "16.0          0.907206       35.4093                  277.865   \n",
       "17.0          0.914727       35.2098                  279.439   \n",
       "18.0          0.914016       35.3415                  278.398   \n",
       "19.0          0.908527       35.3754                  278.131   \n",
       "20.0          0.911881       35.7025                  275.583   \n",
       "21.0          0.914117       35.5389                  276.851   \n",
       "22.0          0.906190       35.4811                  277.303   \n",
       "23.0          0.914829       35.7574                  275.160   \n",
       "24.0          0.917878       36.0625                  272.832   \n",
       "25.0          0.917370       36.0406                  272.998   \n",
       "26.0          0.918691       35.5360                  276.875   \n",
       "27.0          0.918183       35.4422                  277.607   \n",
       "28.0          0.919301       35.3734                  278.147   \n",
       "29.0          0.918793       35.3744                  278.139   \n",
       "30.0          0.919097       35.3604                  278.249   \n",
       "\n",
       "       eval_steps_per_second  train_runtime  train_samples_per_second  \\\n",
       "epoch                                                                   \n",
       "1.0                    4.244          0.000                     0.000   \n",
       "2.0                    4.369          0.000                     0.000   \n",
       "3.0                    4.346          0.000                     0.000   \n",
       "4.0                    4.334          0.000                     0.000   \n",
       "5.0                    4.354          0.000                     0.000   \n",
       "6.0                    4.361          0.000                     0.000   \n",
       "7.0                    4.356          0.000                     0.000   \n",
       "8.0                    4.367          0.000                     0.000   \n",
       "9.0                    4.367          0.000                     0.000   \n",
       "10.0                   4.367          0.000                     0.000   \n",
       "11.0                   4.363          0.000                     0.000   \n",
       "12.0                   4.363          0.000                     0.000   \n",
       "13.0                   4.355          0.000                     0.000   \n",
       "14.0                   4.366          0.000                     0.000   \n",
       "15.0                   4.345          0.000                     0.000   \n",
       "16.0                   4.349          0.000                     0.000   \n",
       "17.0                   4.374          0.000                     0.000   \n",
       "18.0                   4.357          0.000                     0.000   \n",
       "19.0                   4.353          0.000                     0.000   \n",
       "20.0                   4.313          0.000                     0.000   \n",
       "21.0                   4.333          0.000                     0.000   \n",
       "22.0                   4.340          0.000                     0.000   \n",
       "23.0                   4.307          0.000                     0.000   \n",
       "24.0                   4.270          0.000                     0.000   \n",
       "25.0                   4.273          0.000                     0.000   \n",
       "26.0                   4.334          0.000                     0.000   \n",
       "27.0                   4.345          0.000                     0.000   \n",
       "28.0                   4.354          0.000                     0.000   \n",
       "29.0                   4.353          0.000                     0.000   \n",
       "30.0                   4.355      10771.479                    95.867   \n",
       "\n",
       "       train_steps_per_second    total_flos  train_loss  \n",
       "epoch                                                    \n",
       "1.0                     0.000  0.000000e+00     0.00000  \n",
       "2.0                     0.000  0.000000e+00     0.00000  \n",
       "3.0                     0.000  0.000000e+00     0.00000  \n",
       "4.0                     0.000  0.000000e+00     0.00000  \n",
       "5.0                     0.000  0.000000e+00     0.00000  \n",
       "6.0                     0.000  0.000000e+00     0.00000  \n",
       "7.0                     0.000  0.000000e+00     0.00000  \n",
       "8.0                     0.000  0.000000e+00     0.00000  \n",
       "9.0                     0.000  0.000000e+00     0.00000  \n",
       "10.0                    0.000  0.000000e+00     0.00000  \n",
       "11.0                    0.000  0.000000e+00     0.00000  \n",
       "12.0                    0.000  0.000000e+00     0.00000  \n",
       "13.0                    0.000  0.000000e+00     0.00000  \n",
       "14.0                    0.000  0.000000e+00     0.00000  \n",
       "15.0                    0.000  0.000000e+00     0.00000  \n",
       "16.0                    0.000  0.000000e+00     0.00000  \n",
       "17.0                    0.000  0.000000e+00     0.00000  \n",
       "18.0                    0.000  0.000000e+00     0.00000  \n",
       "19.0                    0.000  0.000000e+00     0.00000  \n",
       "20.0                    0.000  0.000000e+00     0.00000  \n",
       "21.0                    0.000  0.000000e+00     0.00000  \n",
       "22.0                    0.000  0.000000e+00     0.00000  \n",
       "23.0                    0.000  0.000000e+00     0.00000  \n",
       "24.0                    0.000  0.000000e+00     0.00000  \n",
       "25.0                    0.000  0.000000e+00     0.00000  \n",
       "26.0                    0.000  0.000000e+00     0.00000  \n",
       "27.0                    0.000  0.000000e+00     0.00000  \n",
       "28.0                    0.000  0.000000e+00     0.00000  \n",
       "29.0                    0.000  0.000000e+00     0.00000  \n",
       "30.0                    2.997  8.003992e+19     0.10811  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_history = pd.DataFrame(trainer.state.log_history)\n",
    "log_history = log_history.fillna(0)\n",
    "log_history = log_history.groupby(['epoch']).sum()\n",
    "log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4707f19-a06a-481c-8b5b-87f5788d4f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./model_large_29_30_280723_200223\n",
      "Configuration saved in ./model_large_29_30_280723_200223\\config.json\n",
      "Model weights saved in ./model_large_29_30_280723_200223\\pytorch_model.bin\n",
      "Image processor saved in ./model_large_29_30_280723_200223\\preprocessor_config.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee6e3c96-4b56-4dd4-80a1-3ea2d295dab8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file C:\\research\\model_large_29_30_280723_200223\\config.json\n",
      "Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224-in21k\",\n",
      "  \"architectures\": [\n",
      "    \"ViTForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"aksessuary\",\n",
      "    \"1\": \"belye\",\n",
      "    \"2\": \"bluzyi\",\n",
      "    \"3\": \"bodi\",\n",
      "    \"4\": \"bryuki\",\n",
      "    \"5\": \"chasy\",\n",
      "    \"6\": \"dublyenki_i_shuby\",\n",
      "    \"7\": \"futbolki\",\n",
      "    \"8\": \"jaketyi\",\n",
      "    \"9\": \"jiletyi\",\n",
      "    \"10\": \"kardiganyi\",\n",
      "    \"11\": \"kombinezony\",\n",
      "    \"12\": \"korsetyi\",\n",
      "    \"13\": \"kyuloty\",\n",
      "    \"14\": \"legginsy\",\n",
      "    \"15\": \"nakidki\",\n",
      "    \"16\": \"obuv\",\n",
      "    \"17\": \"platya\",\n",
      "    \"18\": \"polo\",\n",
      "    \"19\": \"shorty\",\n",
      "    \"20\": \"sumki\",\n",
      "    \"21\": \"topyi\",\n",
      "    \"22\": \"trikotaj\",\n",
      "    \"23\": \"verkhnyaya\",\n",
      "    \"24\": \"vintazh\",\n",
      "    \"25\": \"vodolazki\",\n",
      "    \"26\": \"women\",\n",
      "    \"27\": \"yubki\",\n",
      "    \"28\": \"yuvelirnye\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"aksessuary\": 0,\n",
      "    \"belye\": 1,\n",
      "    \"bluzyi\": 2,\n",
      "    \"bodi\": 3,\n",
      "    \"bryuki\": 4,\n",
      "    \"chasy\": 5,\n",
      "    \"dublyenki_i_shuby\": 6,\n",
      "    \"futbolki\": 7,\n",
      "    \"jaketyi\": 8,\n",
      "    \"jiletyi\": 9,\n",
      "    \"kardiganyi\": 10,\n",
      "    \"kombinezony\": 11,\n",
      "    \"korsetyi\": 12,\n",
      "    \"kyuloty\": 13,\n",
      "    \"legginsy\": 14,\n",
      "    \"nakidki\": 15,\n",
      "    \"obuv\": 16,\n",
      "    \"platya\": 17,\n",
      "    \"polo\": 18,\n",
      "    \"shorty\": 19,\n",
      "    \"sumki\": 20,\n",
      "    \"topyi\": 21,\n",
      "    \"trikotaj\": 22,\n",
      "    \"verkhnyaya\": 23,\n",
      "    \"vintazh\": 24,\n",
      "    \"vodolazki\": 25,\n",
      "    \"women\": 26,\n",
      "    \"yubki\": 27,\n",
      "    \"yuvelirnye\": 28\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qkv_bias\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "loading weights file C:\\research\\model_large_29_30_280723_200223\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ViTForImageClassification.\n",
      "\n",
      "All the weights of ViTForImageClassification were initialized from the model checkpoint at C:\\research\\model_large_29_30_280723_200223.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ViTForImageClassification for predictions without further training.\n",
      "loading configuration file C:\\research\\model_large_29_30_280723_200223\\preprocessor_config.json\n",
      "Image processor ViTFeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"image_processor_type\": \"ViTFeatureExtractor\",\n",
      "  \"image_std\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  }\n",
      "}\n",
      "\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4913\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='615' max='615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [615/615 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6878405213356018, 'eval_accuracy': 0.9198046000407083, 'eval_accuracy_k': 0.9198046000407083, 'eval_runtime': 21.742, 'eval_samples_per_second': 225.968, 'eval_steps_per_second': 28.286}\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "model_dir = 'C:\\\\research\\\\model_large_29_30_280723_200223'\n",
    "test_save_path = 'C:\\\\research\\\\data\\\\processed_dataset\\\\test'\n",
    "test_dataset = load_from_disk(test_save_path)\n",
    "# Load trained model\n",
    "model = ViTForImageClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Load feature extractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_dir)\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=default_data_collator,\n",
    "    tokenizer=feature_extractor\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "eval_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "\n",
    "print(eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
